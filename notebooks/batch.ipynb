{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec7656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558870bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/santari/Projects/pred2control/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9d5d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/home/santari/Projects/pred2control/data/pred2control_target.pt\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7376c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = torch.load(DATA_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53828610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['episodes', 'meta', 'fps', 'action_dim'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(payload))\n",
    "payload.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a2af6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_id': 0, 'category': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload[\"meta\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7d3fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 50 episodes\n",
      "Categories: Counter({1: 10, 2: 10, 3: 10, 4: 10, 5: 10})\n"
     ]
    }
   ],
   "source": [
    "episodes = payload[\"episodes\"]\n",
    "meta = payload[\"meta\"]\n",
    "\n",
    "assert len(episodes) == len(meta)\n",
    "assert all(ep.shape == (300, 6) for ep in episodes), \"Expected all episodes to be (300,6)\"\n",
    "\n",
    "\n",
    "print(\"Loaded:\", len(episodes), \"episodes\")\n",
    "print(\"Categories:\", Counter([m[\"category\"] for m in meta]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db5ef774",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 67\n",
    "TEST_PER_CATERGORY = 3\n",
    "EPS = 1e-6\n",
    "L = 150 # context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ce0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(SEED)\n",
    "\n",
    "cat_to_ids = defaultdict(list)\n",
    "for i, m in enumerate(meta):\n",
    "    cat_to_ids[int(m[\"category\"])].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3497d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "dict_keys([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# check the episodes in this category (1-5)\n",
    "print(cat_to_ids[5])\n",
    "print(cat_to_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad04314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 35 Test: 15\n",
      "Train cats: Counter({1: 7, 2: 7, 3: 7, 4: 7, 5: 7})\n",
      "Test cats: Counter({1: 3, 2: 3, 3: 3, 4: 3, 5: 3})\n"
     ]
    }
   ],
   "source": [
    "train_ids, test_ids = [], []\n",
    "\n",
    "for cat in cat_to_ids.keys():\n",
    "    ids = cat_to_ids[cat]\n",
    "    rng.shuffle(ids)\n",
    "    test = ids[:TEST_PER_CATERGORY]\n",
    "    train = ids[TEST_PER_CATERGORY:]\n",
    "    test_ids.extend(test)\n",
    "    train_ids.extend(train)\n",
    "\n",
    "train_ids = sorted(train_ids)\n",
    "test_ids = sorted(test_ids)\n",
    "\n",
    "\n",
    "print(\"Train:\", len(train_ids), \"Test:\", len(test_ids))  # should be 35 / 15\n",
    "print(\"Train cats:\", Counter([meta[i][\"category\"] for i in train_ids]))\n",
    "print(\"Test cats:\", Counter([meta[i][\"category\"] for i in test_ids]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb483d86",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c30dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([ -3.5770, -45.7268,  32.1744,  74.3475,  -2.3436,   0.5599])\n",
      "std : tensor([14.9339, 54.8193, 55.3805, 10.9193,  3.7141,  0.1235])\n"
     ]
    }
   ],
   "source": [
    "def fit_action_normalizer(episodes_list, eps=1e-6):\n",
    "    # episodes_list: list of (T,6) CPU tensors\n",
    "    total = torch.zeros(6)\n",
    "    total2 = torch.zeros(6)\n",
    "    count = 0\n",
    "\n",
    "    for ep in episodes_list:\n",
    "        ep = ep.float()\n",
    "        total += ep.sum(dim=0)\n",
    "        total2 += (ep * ep).sum(dim=0)\n",
    "        count += ep.shape[0]\n",
    "\n",
    "    mean = total / count\n",
    "    var = total2 / count - mean * mean\n",
    "    std = torch.sqrt(torch.clamp(var, min=eps))\n",
    "    return mean, std\n",
    "\n",
    "train_eps = [episodes[i] for i in train_ids]\n",
    "test_eps  = [episodes[i] for i in test_ids]\n",
    "\n",
    "mean, std = fit_action_normalizer(train_eps, EPS)\n",
    "print(\"mean:\", mean)\n",
    "print(\"std :\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a463c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm train mean: tensor([ 4.0690e-08,  2.9337e-08,  1.1626e-07,  9.3006e-07, -1.0536e-08,\n",
      "         1.3551e-07])\n",
      "norm train std : tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "def normalize_episode(ep, mean, std):\n",
    "    return (ep.float() - mean) / (std + EPS)\n",
    "\n",
    "train_eps_n = [normalize_episode(ep, mean, std) for ep in train_eps]\n",
    "test_eps_n  = [normalize_episode(ep, mean, std) for ep in test_eps]\n",
    "\n",
    "# quick sanity check: train normalized should have ~0 mean, ~1 std\n",
    "all_train = torch.cat(train_eps_n, dim=0)\n",
    "print(\"norm train mean:\", all_train.mean(dim=0))\n",
    "print(\"norm train std :\", all_train.std(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce8a5939",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_eps_n\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_eps_n.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51552fe4",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe94ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_batch_stage2(episodes, batch_size, L=150):\n",
    "    B = batch_size\n",
    "    X = torch.empty(B, L, 6, dtype=torch.float32)\n",
    "    Y = torch.empty(B, 6, dtype=torch.float32)\n",
    "\n",
    "    for b in range(B):\n",
    "        ep = episodes[np.random.randint(0, len(episodes))]\n",
    "        t = np.random.randint(L, 300)  # target index\n",
    "        X[b] = ep[t-L:t]\n",
    "        Y[b] = ep[t]\n",
    "    return X, Y\n",
    "\n",
    "# smoke test\n",
    "X, Y = sample_batch_stage2(train_eps_n, batch_size=8, L=L)\n",
    "print(X.shape, Y.shape)  # (8,150,6) (8,6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
