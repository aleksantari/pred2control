{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38ea8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset \n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c67ebb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/santari/Projects/pred2control/notebooks'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0d91b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"aleksantari/pred2control_target\"\n",
    "OUT_PATH = \"../data/pred2control_target.pt\"\n",
    "\n",
    "dataset = LeRobotDataset(repo_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067993d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34a05832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeRobotDataset({\n",
       "    Repository ID: 'aleksantari/pred2control_target',\n",
       "    Number of selected episodes: '50',\n",
       "    Number of selected samples: '15000',\n",
       "    Features: '['action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index']',\n",
       "})',"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1d3967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7246dbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lerobot.datasets.lerobot_dataset.LeRobotDataset"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7ee861f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': {'dtype': 'float32',\n",
       "  'names': ['shoulder_pan.pos',\n",
       "   'shoulder_lift.pos',\n",
       "   'elbow_flex.pos',\n",
       "   'wrist_flex.pos',\n",
       "   'wrist_roll.pos',\n",
       "   'gripper.pos'],\n",
       "  'shape': (6,)},\n",
       " 'observation.state': {'dtype': 'float32',\n",
       "  'names': ['shoulder_pan.pos',\n",
       "   'shoulder_lift.pos',\n",
       "   'elbow_flex.pos',\n",
       "   'wrist_flex.pos',\n",
       "   'wrist_roll.pos',\n",
       "   'gripper.pos'],\n",
       "  'shape': (6,)},\n",
       " 'timestamp': {'dtype': 'float32', 'shape': (1,), 'names': None},\n",
       " 'frame_index': {'dtype': 'int64', 'shape': (1,), 'names': None},\n",
       " 'episode_index': {'dtype': 'int64', 'shape': (1,), 'names': None},\n",
       " 'index': {'dtype': 'int64', 'shape': (1,), 'names': None},\n",
       " 'task_index': {'dtype': 'int64', 'shape': (1,), 'names': None}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "821a0921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'task'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# main keys for a single sample\n",
    "test_sample = dataset[1] \n",
    "print(test_sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "484c0697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': tensor([ -6.5605, -85.3180,  89.4975,  68.0070,   3.1013,   0.9934]),\n",
       " 'observation.state': tensor([ -2.5660, -79.8212,  80.3114,  79.1123,   3.2967,   0.8368]),\n",
       " 'timestamp': tensor(0.0333),\n",
       " 'frame_index': tensor(1),\n",
       " 'episode_index': tensor(0),\n",
       " 'index': tensor(1),\n",
       " 'task_index': tensor(0),\n",
       " 'task': 'Home -> shared prefix -> branch -> reach target (no gripper)'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "752cd9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -6.5605, -85.3180,  89.4975,  68.0070,   3.1013,   0.9934])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample[\"action\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cd537c",
   "metadata": {},
   "source": [
    "\n",
    "The dataset is one giant list. So we will seperate by episode and include the category \n",
    "\n",
    "\n",
    "1:direct,\n",
    "2:left arc,\n",
    "3:right arc,\n",
    "4:combined,\n",
    "5:random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b199ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_actions = defaultdict(list)\n",
    "episode_category = {}\n",
    "\n",
    "# for all sample in the dataset\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i] # extract sampe \n",
    "    ep = int(sample[\"episode_index\"]) # what episode is this a part of\n",
    "\n",
    "    a  = torch.as_tensor(sample[\"action\"], dtype=torch.float32)  # (6,), extract the action from this sample\n",
    "    episode_actions[ep].append(a) # add to this episode in our new dict\n",
    "\n",
    "    if ep not in episode_category:\n",
    "        episode_category[ep] = ep // 10 + 1 # use floor division to assign this sample a category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69ea56f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 2, 11: 2, 12: 2, 13: 2, 14: 2, 15: 2, 16: 2, 17: 2, 18: 2, 19: 2, 20: 3, 21: 3, 22: 3, 23: 3, 24: 3, 25: 3, 26: 3, 27: 3, 28: 3, 29: 3, 30: 4, 31: 4, 32: 4, 33: 4, 34: 4, 35: 4, 36: 4, 37: 4, 38: 4, 39: 4, 40: 5, 41: 5, 42: 5, 43: 5, 44: 5, 45: 5, 46: 5, 47: 5, 48: 5, 49: 5}\n"
     ]
    }
   ],
   "source": [
    "print(episode_actions.keys())\n",
    "print(episode_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9492cf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(episode_actions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44587b1",
   "metadata": {},
   "source": [
    "we want these lists of actions to be tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee8208b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 50 episodes\n",
      "Example: torch.Size([300, 6]) {'episode_id': 0, 'category': 1}\n"
     ]
    }
   ],
   "source": [
    "episodes, meta = [], []\n",
    "\n",
    "for ep_id in sorted(episode_actions.keys()):\n",
    "    ep_tensor = torch.stack(episode_actions[ep_id], dim=0) # (T, 6)\n",
    "    episodes.append(ep_tensor)\n",
    "\n",
    "    meta.append({\n",
    "        \"episode_id\": ep_id,\n",
    "        \"category\": int(episode_category[ep_id])\n",
    "    })\n",
    "\n",
    "payload = {\n",
    "    \"episodes\": episodes,\n",
    "    \"meta\": meta,\n",
    "    \"fps\": 30, \n",
    "    \"action_dim\": 6,\n",
    "}\n",
    "\n",
    "torch.save(payload, OUT_PATH)\n",
    "print(\"Saved:\", len(episodes), \"episodes\")\n",
    "print(\"Example:\", episodes[0].shape, meta[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5223c42",
   "metadata": {},
   "source": [
    "sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d127019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    }
   ],
   "source": [
    "lengths = [ep.shape[0] for ep in episodes]\n",
    "print(min(lengths), max(lengths))\n",
    "assert all(ep.shape[1] == 6 for ep in episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51356138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 10, 2: 10, 3: 10, 4: 10, 5: 10})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cats = [m[\"category\"] for m in meta]\n",
    "print(Counter(cats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c3269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
